{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing division of wines into quality label \n",
    "## High is 7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' statements to import libraries'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from scipy.stats import kurtosis\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pd.set_option('display.width', 1000)  # Set the maximum width of the display\n",
    "pd.set_option('display.max_columns', None)  # Display all columns without truncation\n",
    "np.set_printoptions(linewidth=150)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality\n",
      "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8        6\n",
      "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5        6\n",
      "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1        6\n",
      "3            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9        6\n",
      "4            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9        6\n",
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality\n",
      "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8        6\n",
      "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5        6\n",
      "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1        6\n",
      "3            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9        6\n",
      "6            6.2              0.32         0.16             7.0      0.045                 30.0                 136.0   0.9949  3.18       0.47      9.6        6\n"
     ]
    }
   ],
   "source": [
    "'''statements to add csv files, remove duplicates etc. Just Red and white individually\n",
    "'''\n",
    "#White wine\n",
    "white_df = pd.read_csv('wine+quality/winequality-white.csv', sep= ';')\n",
    "white_copy = white_df.copy()\n",
    "white_copy.columns = white_copy.columns.str.replace(' ', '_')\n",
    "print(white_copy.head())\n",
    "\n",
    "white_copy = white_copy.drop_duplicates()\n",
    "print(white_copy.head())\n",
    "\n",
    "if 'colour' not in white_copy.columns:\n",
    "    white_copy['colour'] = 'white'\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#Red wine\n",
    "red_df = pd.read_csv('wine+quality/winequality-red.csv', sep = ';')\n",
    "red_copy = red_df.copy()\n",
    "if 'colour' not in red_copy.columns:\n",
    "    red_copy['colour'] = 'red'\n",
    "else:\n",
    "    pass\n",
    "\n",
    "red_copy.columns = red_copy.columns.str.replace(' ', '_')\n",
    "red_copy = red_copy.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' add new column to wine_quality\n",
    "low <= 5\n",
    "5 < medium < 7\n",
    "high >= 7\n",
    "'''\n",
    "if 'quality_label' not in white_copy.columns:\n",
    "    white_copy['quality_label'] = white_copy.quality.apply(lambda value: 'low' if value <= 5 else 'medium' if value < 7 else 'high')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "if 'quality_label' not in red_copy.columns:\n",
    "    red_copy['quality_label'] = red_copy.quality.apply(lambda value: 'low' if value <= 5 else 'medium' if value < 7 else 'high')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "'''add new Column wine_type'''\n",
    "if 'wine_type' not in white_copy.columns:\n",
    "    white_copy['wine_type'] = white_copy.quality.apply(lambda value: 'white')\n",
    "else:\n",
    "    pass\n",
    "if 'wine_type' not in red_copy.columns:\n",
    "    red_copy['wine_type'] = red_copy.quality.apply(lambda value: 'red')\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''making Good Medium Bad have a specified order'''\n",
    "# category_order = ['low', 'medium', 'high']\n",
    "# red_copy['quality_label'] = red_copy['quality_label'].astype(CategoricalDtype(categories=category_order, ordered=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''combining DFs and creating white_red_df'''\n",
    "\n",
    "white_red_df = pd.concat([white_copy, red_copy])\n",
    "white_red_copy = white_red_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = white_red_df.quality_label.value_counts()\n",
    "plt.figure(figsize= (3,3))\n",
    "sns.set(style = 'whitegrid')\n",
    "plt.pie(label_counts, labels = label_counts.index, autopct = '%1.1f%%', startangle = 90)\n",
    "plt.title('Distribution of low, medium, hight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>colour</th>\n",
       "      <th>quality_label</th>\n",
       "      <th>wine_type_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>medium</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality colour quality_label  wine_type_white\n",
       "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8        6  white        medium              1.0\n",
       "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5        6  white        medium              1.0\n",
       "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1        6  white        medium              1.0\n",
       "3            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9        6  white        medium              1.0\n",
       "6            6.2              0.32         0.16             7.0      0.045                 30.0                 136.0   0.9949  3.18       0.47      9.6        6  white        medium              1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''lets encode the data'''\n",
    "encoder = OneHotEncoder(handle_unknown= 'ignore', sparse_output= False).set_output(transform= 'pandas')\n",
    "\n",
    "colour_encoded_data = encoder.fit_transform(white_red_copy[['wine_type']])\n",
    "if 'wine_type' in white_red_copy.columns:\n",
    "    ml_df = pd.concat([white_red_copy, colour_encoded_data], axis= 1)\n",
    "#print(white_red_copy.columns)\n",
    "#ml_df = white_red_copy[['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar','chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       #'pH', 'sulphates', 'alcohol', 'quality','wine_type_red']]\n",
    "if 'wine_type' in ml_df.columns:\n",
    "    ml_df.drop('wine_type', axis=1, inplace= True)\n",
    "    ml_df.drop('wine_type_red', axis = 1, inplace = True)\n",
    "    #ml_df.drop(['quality', 'quality_label', 'colour'], axis=1, inplace= True)\n",
    "display (ml_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['low', 'medium', 'high']], dtype='<U6')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['low', 'medium', 'high']\n",
    "categories = np.reshape(categories, (1, -1))\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  quality colour  quality_label  wine_type_white  quality_label_encoded\n",
      "1577            6.2             0.700         0.15             5.1      0.076                 13.0                  27.0  0.99622  3.54       0.60     11.9        6    red              1              0.0                      1\n",
      "1578            6.8             0.670         0.15             1.8      0.118                 13.0                  20.0  0.99540  3.42       0.67     11.3        6    red              1              0.0                      1\n",
      "1579            6.2             0.560         0.09             1.7      0.053                 24.0                  32.0  0.99402  3.54       0.60     11.3        5    red              0              0.0                      0\n",
      "1580            7.4             0.350         0.33             2.4      0.068                  9.0                  26.0  0.99470  3.36       0.60     11.9        6    red              1              0.0                      1\n",
      "1582            6.1             0.715         0.10             2.6      0.053                 13.0                  27.0  0.99362  3.57       0.50     11.9        5    red              0              0.0                      0\n",
      "1583            6.2             0.460         0.29             2.1      0.074                 32.0                  98.0  0.99578  3.33       0.62      9.8        5    red              0              0.0                      0\n",
      "1584            6.7             0.320         0.44             2.4      0.061                 24.0                  34.0  0.99484  3.29       0.80     11.6        7    red              2              0.0                      2\n",
      "1585            7.2             0.390         0.44             2.6      0.066                 22.0                  48.0  0.99494  3.30       0.84     11.5        6    red              1              0.0                      1\n",
      "1586            7.5             0.310         0.41             2.4      0.065                 34.0                  60.0  0.99492  3.34       0.85     11.4        6    red              1              0.0                      1\n",
      "1587            5.8             0.610         0.11             1.8      0.066                 18.0                  28.0  0.99483  3.55       0.66     10.9        6    red              1              0.0                      1\n",
      "1588            7.2             0.660         0.33             2.5      0.068                 34.0                 102.0  0.99414  3.27       0.78     12.8        6    red              1              0.0                      1\n",
      "1589            6.6             0.725         0.20             7.8      0.073                 29.0                  79.0  0.99770  3.29       0.54      9.2        5    red              0              0.0                      0\n",
      "1590            6.3             0.550         0.15             1.8      0.077                 26.0                  35.0  0.99314  3.32       0.82     11.6        6    red              1              0.0                      1\n",
      "1591            5.4             0.740         0.09             1.7      0.089                 16.0                  26.0  0.99402  3.67       0.56     11.6        6    red              1              0.0                      1\n",
      "1592            6.3             0.510         0.13             2.3      0.076                 29.0                  40.0  0.99574  3.42       0.75     11.0        6    red              1              0.0                      1\n",
      "1593            6.8             0.620         0.08             1.9      0.068                 28.0                  38.0  0.99651  3.42       0.82      9.5        6    red              1              0.0                      1\n",
      "1594            6.2             0.600         0.08             2.0      0.090                 32.0                  44.0  0.99490  3.45       0.58     10.5        5    red              0              0.0                      0\n",
      "1595            5.9             0.550         0.10             2.2      0.062                 39.0                  51.0  0.99512  3.52       0.76     11.2        6    red              1              0.0                      1\n",
      "1597            5.9             0.645         0.12             2.0      0.075                 32.0                  44.0  0.99547  3.57       0.71     10.2        5    red              0              0.0                      0\n",
      "1598            6.0             0.310         0.47             3.6      0.067                 18.0                  42.0  0.99549  3.39       0.66     11.0        6    red              1              0.0                      1\n"
     ]
    }
   ],
   "source": [
    "''' lets use label encoder to encode the wine_quality\n",
    "we cannot use onehot encoder as that only does binary, dichotomous choices\n",
    "low 1\n",
    "medium 2\n",
    "high 0\n",
    "'''\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# from sklearn.preprocessing import OrdinalEncoder\n",
    "# categories = ['low', 'medium', 'high']\n",
    "# categories = np.reshape(categories, (1, -1))\n",
    "# oe = OrdinalEncoder(categories = ['low', 'medium', 'high'])\n",
    "# ml_df['quality_label_encoded'] = oe.fit_transform(ml_df['quality_label'])\n",
    "# print(ml_df.head(20))\n",
    "# display(ml_df.info())\n",
    "\n",
    "quality_codes = {'low' : 0, 'medium': 1, 'high':2}\n",
    "\n",
    "ml_df['quality_label'].replace(quality_codes, inplace= True)\n",
    "ml_df['quality_label_encoded'] = ml_df.quality_label\n",
    "print(ml_df.tail(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>wine_type_white</th>\n",
       "      <th>quality_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  wine_type_white  quality_label_encoded\n",
       "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8              1.0                      1\n",
       "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5              1.0                      1\n",
       "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1              1.0                      1\n",
       "3            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9              1.0                      1\n",
       "6            6.2              0.32         0.16             7.0      0.045                 30.0                 136.0   0.9949  3.18       0.47      9.6              1.0                      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' drop other unwanted columns: quality_label, colour, quality'''\n",
    "for val in ['quality_label','colour', 'quality', 'wine_type']:\n",
    "    if val in ml_df.columns:\n",
    "        ml_df.drop(val, axis =1, inplace= True)\n",
    "display(ml_df.head())\n",
    "ml_df2 = ml_df.copy().reset_index()\n",
    "\n",
    "ml_df2.to_csv('whole_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      quality_label_encoded\n",
      "3207                      1\n",
      "612                       0\n",
      "71                        0\n",
      "3857                      1\n",
      "312                       1\n",
      "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  wine_type_white\n",
      "3207            6.8              0.21         0.42             1.2      0.045                 24.0                 126.0  0.99234  3.09       0.87     10.9              1.0\n",
      "612             7.5              0.23         0.68            11.0      0.047                 37.0                 133.0  0.99780  2.99       0.38      8.8              1.0\n",
      "71              6.8              0.30         0.23             4.6      0.061                 50.5                 238.5  0.99580  3.32       0.60      9.5              1.0\n",
      "3857            5.4              0.17         0.27             2.7      0.049                 28.0                 104.0  0.99224  3.46       0.55     10.3              1.0\n",
      "312             9.0              0.46         0.31             2.8      0.093                 19.0                  98.0  0.99815  3.32       0.63      9.5              0.0\n"
     ]
    }
   ],
   "source": [
    "''' split the data'''\n",
    "X_train, x_test, Y_train, y_test = train_test_split( ml_df.iloc[:,:-1],ml_df.iloc[:, -1:], test_size = 0.2, random_state = 42)\n",
    "# display(X_train.shape)\n",
    "# display(x_test.shape)\n",
    "# display(Y_train.shape)\n",
    "# display(y_test.shape)\n",
    "print(Y_train.head())\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.81"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_regress(X_train, Y_train, x_test, y_test, graph):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    Y_train = np.ravel(Y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    lr = LogisticRegression(random_state = 42, max_iter = 10000, multi_class= 'multinomial')\n",
    "    lr.fit(X_train, Y_train)\n",
    "    pred_lr = lr.predict(x_test)\n",
    "    confu_mat = confusion_matrix(y_test, pred_lr)\n",
    "    accuracy_percentage = round(accuracy_score(y_test, pred_lr) * 100,2)\n",
    "    #print(\"Accuracy of Logistic Regression:\", accuracy_percentage, \"%\")\n",
    "    \n",
    "#printing a graph of the heatmap\n",
    "    if graph == True:\n",
    "        sns.heatmap(confu_mat, annot=True, fmt= 'g', cmap = 'Blues')\n",
    "        plt.suptitle('Logistic Regression Confusion Map')        \n",
    "        plt.show()\n",
    "    return accuracy_percentage\n",
    "log_regress(X_train, Y_train, x_test, y_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''neighbours classifier''' \n",
    "def neigh_class(X_train, Y_train, x_test, y_test, graph):\n",
    "    Y_train = np.ravel(Y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    accuracy_percentage = (knn.score(x_test, y_test) * 100).round(2)\n",
    "    #print(\"Accuracy of Neighbours Classifier:\", accuracy_percentage, \"%\")\n",
    "    pred_neighbours = knn.predict(x_test)\n",
    "    confu_mat = confusion_matrix(y_test, pred_neighbours)    \n",
    "    if graph == True:\n",
    "        sns.heatmap(confu_mat, annot=True, fmt= 'g', cmap = 'Blues')\n",
    "        plt.suptitle('Random Forest Confusion Map')\n",
    "        plt.show()\n",
    "    #print('________________')\n",
    "    return accuracy_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''decision tree'''\n",
    "def dec_tree(X_train, Y_train, x_test, y_test, graph):\n",
    "    \n",
    "    Y_train = np.ravel(Y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    tree.fit(X_train, Y_train)\n",
    "    accuracy_percentage = (tree.score(x_test, y_test) * 100).round(2)\n",
    "    #print(\"Accuracy of Decision Tree:\", accuracy_percentage, \"%\")\n",
    "    pred_tree = tree.predict(x_test)\n",
    "    confu_mat = confusion_matrix(y_test, pred_tree)\n",
    "    plt.show()\n",
    "    if graph == True:\n",
    "        sns.heatmap(confu_mat, annot=True, fmt= 'g', cmap = 'Blues')\n",
    "        plt.suptitle('Decision Tree Confusion Map')\n",
    "        plt.show()\n",
    "    \n",
    "    #print('________________')\n",
    "    return accuracy_percentage\n",
    "\n",
    "dec_tree(X_train, Y_train, x_test, y_test, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''random forest'''\n",
    "def ran_forest(X_train, Y_train, x_test, y_test, graph) :\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    Y_train = np.ravel(Y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 10)\n",
    "    forest.fit(X_train, Y_train)\n",
    "    accuracy_percentage = (forest.score(x_test, y_test) * 100).round(2)\n",
    "    pred_forest = forest.predict(x_test)\n",
    "    confu_mat = confusion_matrix(y_test, pred_forest)\n",
    "    \n",
    "    #print(\"Accuracy of Random Forest:\", accuracy_percentage, \"%\")    \n",
    "    if graph == True:\n",
    "        sns.heatmap(confu_mat, annot=True, fmt= 'g', cmap = 'Blues')\n",
    "        plt.suptitle('Random Forest Confusion Map')\n",
    "        plt.show()\n",
    "    #print('________________')\n",
    "    return accuracy_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Linear regression'''\n",
    "def lin_reg(X_train, Y_train, x_test, y_test):\n",
    "    Y_train = np.ravel(Y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    from sklearn import linear_model\n",
    "    linreg = linear_model.LinearRegression()\n",
    "    linreg.fit(X_train, Y_train)\n",
    "    accuracy_percentage = (linreg.score(x_test, y_test) * 100).round(2)\n",
    "    pred_linreg = linreg.predict(x_test)\n",
    "\n",
    "    #print(\"Accuracy of Linear Regression:\", accuracy_percentage, \"%\")\n",
    "    #print('________________')\n",
    "    return accuracy_percentage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_regress(X_train, Y_train, x_test, y_test, False)\n",
    "#lin_reg(X_train, Y_train, x_test, y_test)\n",
    "# neigh_class(X_train, Y_train, x_test, y_test, False),\n",
    "# dec_tree(X_train, Y_train, x_test, y_test, False),\n",
    "# ran_forest(X_train, Y_train, x_test, y_test, False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>60.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbours Classifier</th>\n",
       "      <td>47.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>51.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>58.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       all_variables\n",
       "Logistic Regression            60.81\n",
       "Linear Regression              35.98\n",
       "Neighbours Classifier          47.09\n",
       "Decision Tree                  51.60\n",
       "Random Forest                  58.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_names = ['Logistic Regression', 'Linear Regression', 'Neighbours Classifier', 'Decision Tree', 'Random Forest']\n",
    "comparison_df = pd.DataFrame(index=index_names)\n",
    "#ml_df = ml_df.drop(['quality'], axis = 1)X_train, x_test, Y_train, y_test = train_test_split( ml_df.iloc[:,:-1],ml_df.iloc[:, -1:], test_size = 0.2, random_state = 42)\n",
    "\n",
    "comparison_df['all_variables'] = [log_regress(X_train, Y_train, x_test, y_test, False),\n",
    "lin_reg(X_train, Y_train, x_test, y_test),\n",
    "neigh_class(X_train, Y_train, x_test, y_test, False),\n",
    "dec_tree(X_train, Y_train, x_test, y_test, False),\n",
    "ran_forest(X_train, Y_train, x_test, y_test, False)]\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' create a correlation matrix between quality_label and the other variables\n",
    "then save it as a sorted list where the names are in order\n",
    "sorted list of \n",
    "\n",
    "'''\n",
    "corr = ml_df.corr()\n",
    "\n",
    "corr_list = corr['quality_label_encoded'][:-1]\n",
    "\n",
    "corr_list = corr_list.apply(lambda x: abs(x))\n",
    "corr_list = corr_list.sort_values()\n",
    "corr_list_names = corr_list.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>60.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neighbours Classifier</th>\n",
       "      <td>47.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>51.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>58.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         all\n",
       "Logistic Regression    60.81\n",
       "Linear Regression      35.98\n",
       "Neighbours Classifier  47.09\n",
       "Decision Tree          51.60\n",
       "Random Forest          58.36"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''create my DF showing the results of my algorithms. WE will start with all columsn'''\n",
    "comparison_df = pd.DataFrame(index=index_names)\n",
    "comparison_df['all'] = [log_regress(X_train, Y_train, x_test, y_test, False),\n",
    "lin_reg(X_train, Y_train, x_test, y_test),\n",
    "neigh_class(X_train, Y_train, x_test, y_test, False),\n",
    "dec_tree(X_train, Y_train, x_test, y_test, False),\n",
    "ran_forest(X_train, Y_train, x_test, y_test, False)]\n",
    "display(comparison_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  alcohol  wine_type_white  quality_label_encoded\n",
      "0            7.0              0.27         0.36            20.7      0.045                 45.0                 170.0   1.0010  3.00       0.45      8.8              1.0                      1\n",
      "1            6.3              0.30         0.34             1.6      0.049                 14.0                 132.0   0.9940  3.30       0.49      9.5              1.0                      1\n",
      "2            8.1              0.28         0.40             6.9      0.050                 30.0                  97.0   0.9951  3.26       0.44     10.1              1.0                      1\n",
      "3            7.2              0.23         0.32             8.5      0.058                 47.0                 186.0   0.9956  3.19       0.40      9.9              1.0                      1\n",
      "6            6.2              0.32         0.16             7.0      0.045                 30.0                 136.0   0.9949  3.18       0.47      9.6              1.0                      1\n"
     ]
    }
   ],
   "source": [
    "print(ml_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' using a for loop we will remove one column at a time based on the columns correlation with our target depenedent variable\n",
    "using our corr_list_names variable '''\n",
    "for val in corr_list_names[:-1]:\n",
    "    ml_df = ml_df.drop([val], axis = 1)\n",
    "    X_train, x_test, Y_train, y_test = train_test_split( ml_df.iloc[:,:-1],ml_df.iloc[:, -1:], test_size = 0.2, random_state = 42)\n",
    "    comparison_df[val] = [log_regress(X_train, Y_train, x_test, y_test, False),\n",
    "    lin_reg(X_train, Y_train, x_test, y_test),\n",
    "    neigh_class(X_train, Y_train, x_test, y_test, False),\n",
    "    dec_tree(X_train, Y_train, x_test, y_test, False),\n",
    "    ran_forest(X_train, Y_train, x_test, y_test, False)]\n",
    "\n",
    "#backwards elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b704c_row0_col1, #T_b704c_row1_col0, #T_b704c_row2_col6, #T_b704c_row3_col11, #T_b704c_row4_col2 {\n",
       "  background-color: lightyellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b704c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b704c_level0_col0\" class=\"col_heading level0 col0\" >all</th>\n",
       "      <th id=\"T_b704c_level0_col1\" class=\"col_heading level0 col1\" >free_sulfur_dioxide</th>\n",
       "      <th id=\"T_b704c_level0_col2\" class=\"col_heading level0 col2\" >sulphates</th>\n",
       "      <th id=\"T_b704c_level0_col3\" class=\"col_heading level0 col3\" >pH</th>\n",
       "      <th id=\"T_b704c_level0_col4\" class=\"col_heading level0 col4\" >total_sulfur_dioxide</th>\n",
       "      <th id=\"T_b704c_level0_col5\" class=\"col_heading level0 col5\" >fixed_acidity</th>\n",
       "      <th id=\"T_b704c_level0_col6\" class=\"col_heading level0 col6\" >residual_sugar</th>\n",
       "      <th id=\"T_b704c_level0_col7\" class=\"col_heading level0 col7\" >citric_acid</th>\n",
       "      <th id=\"T_b704c_level0_col8\" class=\"col_heading level0 col8\" >wine_type_white</th>\n",
       "      <th id=\"T_b704c_level0_col9\" class=\"col_heading level0 col9\" >chlorides</th>\n",
       "      <th id=\"T_b704c_level0_col10\" class=\"col_heading level0 col10\" >volatile_acidity</th>\n",
       "      <th id=\"T_b704c_level0_col11\" class=\"col_heading level0 col11\" >density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_b704c_row0_col0\" class=\"data row0 col0\" >60.810000</td>\n",
       "      <td id=\"T_b704c_row0_col1\" class=\"data row0 col1\" >61.000000</td>\n",
       "      <td id=\"T_b704c_row0_col2\" class=\"data row0 col2\" >60.710000</td>\n",
       "      <td id=\"T_b704c_row0_col3\" class=\"data row0 col3\" >59.400000</td>\n",
       "      <td id=\"T_b704c_row0_col4\" class=\"data row0 col4\" >59.210000</td>\n",
       "      <td id=\"T_b704c_row0_col5\" class=\"data row0 col5\" >59.770000</td>\n",
       "      <td id=\"T_b704c_row0_col6\" class=\"data row0 col6\" >59.120000</td>\n",
       "      <td id=\"T_b704c_row0_col7\" class=\"data row0 col7\" >58.830000</td>\n",
       "      <td id=\"T_b704c_row0_col8\" class=\"data row0 col8\" >58.930000</td>\n",
       "      <td id=\"T_b704c_row0_col9\" class=\"data row0 col9\" >58.740000</td>\n",
       "      <td id=\"T_b704c_row0_col10\" class=\"data row0 col10\" >54.610000</td>\n",
       "      <td id=\"T_b704c_row0_col11\" class=\"data row0 col11\" >54.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row1\" class=\"row_heading level0 row1\" >Linear Regression</th>\n",
       "      <td id=\"T_b704c_row1_col0\" class=\"data row1 col0\" >35.980000</td>\n",
       "      <td id=\"T_b704c_row1_col1\" class=\"data row1 col1\" >35.550000</td>\n",
       "      <td id=\"T_b704c_row1_col2\" class=\"data row1 col2\" >34.240000</td>\n",
       "      <td id=\"T_b704c_row1_col3\" class=\"data row1 col3\" >33.670000</td>\n",
       "      <td id=\"T_b704c_row1_col4\" class=\"data row1 col4\" >33.660000</td>\n",
       "      <td id=\"T_b704c_row1_col5\" class=\"data row1 col5\" >33.720000</td>\n",
       "      <td id=\"T_b704c_row1_col6\" class=\"data row1 col6\" >33.620000</td>\n",
       "      <td id=\"T_b704c_row1_col7\" class=\"data row1 col7\" >33.630000</td>\n",
       "      <td id=\"T_b704c_row1_col8\" class=\"data row1 col8\" >33.540000</td>\n",
       "      <td id=\"T_b704c_row1_col9\" class=\"data row1 col9\" >33.530000</td>\n",
       "      <td id=\"T_b704c_row1_col10\" class=\"data row1 col10\" >26.260000</td>\n",
       "      <td id=\"T_b704c_row1_col11\" class=\"data row1 col11\" >26.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row2\" class=\"row_heading level0 row2\" >Neighbours Classifier</th>\n",
       "      <td id=\"T_b704c_row2_col0\" class=\"data row2 col0\" >47.090000</td>\n",
       "      <td id=\"T_b704c_row2_col1\" class=\"data row2 col1\" >49.250000</td>\n",
       "      <td id=\"T_b704c_row2_col2\" class=\"data row2 col2\" >49.910000</td>\n",
       "      <td id=\"T_b704c_row2_col3\" class=\"data row2 col3\" >49.810000</td>\n",
       "      <td id=\"T_b704c_row2_col4\" class=\"data row2 col4\" >53.670000</td>\n",
       "      <td id=\"T_b704c_row2_col5\" class=\"data row2 col5\" >52.630000</td>\n",
       "      <td id=\"T_b704c_row2_col6\" class=\"data row2 col6\" >53.850000</td>\n",
       "      <td id=\"T_b704c_row2_col7\" class=\"data row2 col7\" >53.760000</td>\n",
       "      <td id=\"T_b704c_row2_col8\" class=\"data row2 col8\" >53.290000</td>\n",
       "      <td id=\"T_b704c_row2_col9\" class=\"data row2 col9\" >51.320000</td>\n",
       "      <td id=\"T_b704c_row2_col10\" class=\"data row2 col10\" >51.320000</td>\n",
       "      <td id=\"T_b704c_row2_col11\" class=\"data row2 col11\" >49.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row3\" class=\"row_heading level0 row3\" >Decision Tree</th>\n",
       "      <td id=\"T_b704c_row3_col0\" class=\"data row3 col0\" >51.600000</td>\n",
       "      <td id=\"T_b704c_row3_col1\" class=\"data row3 col1\" >51.880000</td>\n",
       "      <td id=\"T_b704c_row3_col2\" class=\"data row3 col2\" >51.220000</td>\n",
       "      <td id=\"T_b704c_row3_col3\" class=\"data row3 col3\" >51.410000</td>\n",
       "      <td id=\"T_b704c_row3_col4\" class=\"data row3 col4\" >51.410000</td>\n",
       "      <td id=\"T_b704c_row3_col5\" class=\"data row3 col5\" >52.070000</td>\n",
       "      <td id=\"T_b704c_row3_col6\" class=\"data row3 col6\" >50.000000</td>\n",
       "      <td id=\"T_b704c_row3_col7\" class=\"data row3 col7\" >46.520000</td>\n",
       "      <td id=\"T_b704c_row3_col8\" class=\"data row3 col8\" >47.270000</td>\n",
       "      <td id=\"T_b704c_row3_col9\" class=\"data row3 col9\" >50.660000</td>\n",
       "      <td id=\"T_b704c_row3_col10\" class=\"data row3 col10\" >48.210000</td>\n",
       "      <td id=\"T_b704c_row3_col11\" class=\"data row3 col11\" >55.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row4\" class=\"row_heading level0 row4\" >Random Forest</th>\n",
       "      <td id=\"T_b704c_row4_col0\" class=\"data row4 col0\" >58.360000</td>\n",
       "      <td id=\"T_b704c_row4_col1\" class=\"data row4 col1\" >57.710000</td>\n",
       "      <td id=\"T_b704c_row4_col2\" class=\"data row4 col2\" >58.550000</td>\n",
       "      <td id=\"T_b704c_row4_col3\" class=\"data row4 col3\" >57.140000</td>\n",
       "      <td id=\"T_b704c_row4_col4\" class=\"data row4 col4\" >56.770000</td>\n",
       "      <td id=\"T_b704c_row4_col5\" class=\"data row4 col5\" >56.480000</td>\n",
       "      <td id=\"T_b704c_row4_col6\" class=\"data row4 col6\" >57.330000</td>\n",
       "      <td id=\"T_b704c_row4_col7\" class=\"data row4 col7\" >56.110000</td>\n",
       "      <td id=\"T_b704c_row4_col8\" class=\"data row4 col8\" >54.610000</td>\n",
       "      <td id=\"T_b704c_row4_col9\" class=\"data row4 col9\" >53.570000</td>\n",
       "      <td id=\"T_b704c_row4_col10\" class=\"data row4 col10\" >49.530000</td>\n",
       "      <td id=\"T_b704c_row4_col11\" class=\"data row4 col11\" >54.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13fa7b510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''adding a style to highlight teh highest value in each row'''\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: lightyellow' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "comparison_df = comparison_df.style.apply(highlight_max, axis = 1)\n",
    "\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work out evaluation metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted', zero_division = 1)\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Playing with K-folds: decision tree'''\n",
    "\n",
    "def dec_tree_kfold(X, Y):\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the decision Tree classifier\n",
    "    tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this should run 5 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        tree.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = tree.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_kfold(X, Y):\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the random forest classifier\n",
    "    tree = RandomForestClassifier(criterion = 'entropy', random_state = 0)\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this should run 5 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        tree.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = tree.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''K-folds for K neighbours KNeighborsClassifier '''\n",
    "def kneigh_class_k(X, Y):\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the kneighbours classifier\n",
    "    knc = KNeighborsClassifier()\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this should run 5 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        knc.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = knc.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Logistic regression for Kfolds'''\n",
    "#Where X is a DF with my dependent variables and Y is a series containing encoded values\n",
    "def log_regress_k(X, Y):\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the decision Tree classifier\n",
    "    lr = LogisticRegression(random_state= 42, max_iter = 1000, multi_class = 'multinomial')\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this for loop should run 3 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        lr.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = lr.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''naive bayes with K-Folds'''\n",
    "\n",
    "#Where X is a DF with my dependent variables and Y is a series containing encoded values\n",
    "def gaussian_NB_k(X, Y):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the decision Tree classifier\n",
    "    gnb = GaussianNB()\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this for loop should run 3 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        gnb.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = gnb.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''support vector K with K-Folds'''\n",
    "\n",
    "#Where X is a DF with my dependent variables and Y is a series containing encoded values\n",
    "def support_vector_k(X, Y):\n",
    "    from sklearn.svm import SVC\n",
    "    Y = np.ravel(Y)\n",
    "    #creating an instance of the decision Tree classifier\n",
    "    svc = SVC()\n",
    "    #how many 'folds' do we want\n",
    "    n_folds = 3\n",
    "    #initialize the StratifiedKFold object\n",
    "    skf = StratifiedKFold(n_splits= n_folds, shuffle = True, random_state=42)\n",
    "    \n",
    "    #used to hold results from each loop \n",
    "    accuracy_list, precision_list, recall_list, f1_list, kappa_list = [], [], [], [], []\n",
    "\n",
    "    #because n_folds= 5 this for loop should run 3 times\n",
    "    #it will return two lists of indexes - 1 for the training: X and 1 for the test: Y\n",
    "    for train, test in skf.split(X ,Y):\n",
    "        #we isolate the appropriate indexes for our training and our testing\n",
    "        X_train_k, X_test_k = X.loc[train], X.loc[test]\n",
    "        y_train_k, y_test_k = Y[train], Y[test]\n",
    "        #we enter our training data in to the instance of DecisionTreeClassifier we created\n",
    "        svc.fit(X_train_k, y_train_k)\n",
    "        #we test our model by entering our test X ie. the DF with our variables we have not used so far\n",
    "        y_pred = svc.predict(X_test_k)\n",
    "        #use the inbuilt compute_metrics to get the accuracy, precision, recall and f1 stats and add them to our container lists\n",
    "        accuracy, precision, recall, f1 = compute_metrics(y_test_k, y_pred)\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        kappa_score = cohen_kappa_score(y_test_k, y_pred)\n",
    "        kappa_list.append(kappa_score)\n",
    "\n",
    "    #get the average of each our run throughs\n",
    "    accuracy = np.mean(accuracy_list)\n",
    "    precision = np.mean(accuracy_list)\n",
    "    recall = np.mean(recall_list)\n",
    "    f1 = np.mean(f1_list)\n",
    "    kappa = np.mean(kappa_list)\n",
    "    return [accuracy, precision, recall, f1, kappa]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df2 = pd.DataFrame(index=['accuracy', 'precision', 'recall', 'f1', 'kappa'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dec_tree_kfold(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n",
    "\n",
    "comparison_df2['Decision_tree_K'] = dec_tree_kfold(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df2['Random_forest_K'] = random_forest_kfold(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df2['K-neighbours_K'] = kneigh_class_k(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barry/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/barry/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/barry/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "comparison_df2['Logistic_regression_K'] = log_regress_k(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df2['gaussian_NB_k'] = gaussian_NB_k(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df2['support_vector_K'] = support_vector_k(ml_df2.iloc[:,:-1], ml_df2.iloc[:, -1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Evaluation metrics for algorithims\n",
    "### Decision_tree_K, Random_forest_K, K-neighbours_K,Logistic_regression_K, gaussian_NB_k, support_vector_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b86de_row0_col1, #T_b86de_row1_col1, #T_b86de_row2_col1, #T_b86de_row3_col1, #T_b86de_row4_col1 {\n",
       "  background-color: lightyellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b86de\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b86de_level0_col0\" class=\"col_heading level0 col0\" >Decision_tree_K</th>\n",
       "      <th id=\"T_b86de_level0_col1\" class=\"col_heading level0 col1\" >Random_forest_K</th>\n",
       "      <th id=\"T_b86de_level0_col2\" class=\"col_heading level0 col2\" >K-neighbours_K</th>\n",
       "      <th id=\"T_b86de_level0_col3\" class=\"col_heading level0 col3\" >Logistic_regression_K</th>\n",
       "      <th id=\"T_b86de_level0_col4\" class=\"col_heading level0 col4\" >gaussian_NB_k</th>\n",
       "      <th id=\"T_b86de_level0_col5\" class=\"col_heading level0 col5\" >support_vector_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b86de_level0_row0\" class=\"row_heading level0 row0\" >accuracy</th>\n",
       "      <td id=\"T_b86de_row0_col0\" class=\"data row0 col0\" >0.521428</td>\n",
       "      <td id=\"T_b86de_row0_col1\" class=\"data row0 col1\" >0.624812</td>\n",
       "      <td id=\"T_b86de_row0_col2\" class=\"data row0 col2\" >0.457143</td>\n",
       "      <td id=\"T_b86de_row0_col3\" class=\"data row0 col3\" >0.530642</td>\n",
       "      <td id=\"T_b86de_row0_col4\" class=\"data row0 col4\" >0.512217</td>\n",
       "      <td id=\"T_b86de_row0_col5\" class=\"data row0 col5\" >0.443045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b86de_level0_row1\" class=\"row_heading level0 row1\" >precision</th>\n",
       "      <td id=\"T_b86de_row1_col0\" class=\"data row1 col0\" >0.521428</td>\n",
       "      <td id=\"T_b86de_row1_col1\" class=\"data row1 col1\" >0.624812</td>\n",
       "      <td id=\"T_b86de_row1_col2\" class=\"data row1 col2\" >0.457143</td>\n",
       "      <td id=\"T_b86de_row1_col3\" class=\"data row1 col3\" >0.530642</td>\n",
       "      <td id=\"T_b86de_row1_col4\" class=\"data row1 col4\" >0.512217</td>\n",
       "      <td id=\"T_b86de_row1_col5\" class=\"data row1 col5\" >0.443045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b86de_level0_row2\" class=\"row_heading level0 row2\" >recall</th>\n",
       "      <td id=\"T_b86de_row2_col0\" class=\"data row2 col0\" >0.521428</td>\n",
       "      <td id=\"T_b86de_row2_col1\" class=\"data row2 col1\" >0.624812</td>\n",
       "      <td id=\"T_b86de_row2_col2\" class=\"data row2 col2\" >0.457143</td>\n",
       "      <td id=\"T_b86de_row2_col3\" class=\"data row2 col3\" >0.530642</td>\n",
       "      <td id=\"T_b86de_row2_col4\" class=\"data row2 col4\" >0.512217</td>\n",
       "      <td id=\"T_b86de_row2_col5\" class=\"data row2 col5\" >0.443045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b86de_level0_row3\" class=\"row_heading level0 row3\" >f1</th>\n",
       "      <td id=\"T_b86de_row3_col0\" class=\"data row3 col0\" >0.521270</td>\n",
       "      <td id=\"T_b86de_row3_col1\" class=\"data row3 col1\" >0.622509</td>\n",
       "      <td id=\"T_b86de_row3_col2\" class=\"data row3 col2\" >0.445852</td>\n",
       "      <td id=\"T_b86de_row3_col3\" class=\"data row3 col3\" >0.526147</td>\n",
       "      <td id=\"T_b86de_row3_col4\" class=\"data row3 col4\" >0.513374</td>\n",
       "      <td id=\"T_b86de_row3_col5\" class=\"data row3 col5\" >0.366791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b86de_level0_row4\" class=\"row_heading level0 row4\" >kappa</th>\n",
       "      <td id=\"T_b86de_row4_col0\" class=\"data row4 col0\" >0.245817</td>\n",
       "      <td id=\"T_b86de_row4_col1\" class=\"data row4 col1\" >0.393599</td>\n",
       "      <td id=\"T_b86de_row4_col2\" class=\"data row4 col2\" >0.115788</td>\n",
       "      <td id=\"T_b86de_row4_col3\" class=\"data row4 col3\" >0.240154</td>\n",
       "      <td id=\"T_b86de_row4_col4\" class=\"data row4 col4\" >0.238977</td>\n",
       "      <td id=\"T_b86de_row4_col5\" class=\"data row4 col5\" >0.033558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1616ee350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison_df3 = comparison_df2.style.apply(highlight_max, axis = 1)\n",
    "display(comparison_df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of algorithms\n",
    "## removing features in consequtive increasing correlation score without returning removed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b704c_row0_col1, #T_b704c_row1_col0, #T_b704c_row2_col6, #T_b704c_row3_col11, #T_b704c_row4_col2 {\n",
       "  background-color: lightyellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b704c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b704c_level0_col0\" class=\"col_heading level0 col0\" >all</th>\n",
       "      <th id=\"T_b704c_level0_col1\" class=\"col_heading level0 col1\" >free_sulfur_dioxide</th>\n",
       "      <th id=\"T_b704c_level0_col2\" class=\"col_heading level0 col2\" >sulphates</th>\n",
       "      <th id=\"T_b704c_level0_col3\" class=\"col_heading level0 col3\" >pH</th>\n",
       "      <th id=\"T_b704c_level0_col4\" class=\"col_heading level0 col4\" >total_sulfur_dioxide</th>\n",
       "      <th id=\"T_b704c_level0_col5\" class=\"col_heading level0 col5\" >fixed_acidity</th>\n",
       "      <th id=\"T_b704c_level0_col6\" class=\"col_heading level0 col6\" >residual_sugar</th>\n",
       "      <th id=\"T_b704c_level0_col7\" class=\"col_heading level0 col7\" >citric_acid</th>\n",
       "      <th id=\"T_b704c_level0_col8\" class=\"col_heading level0 col8\" >wine_type_white</th>\n",
       "      <th id=\"T_b704c_level0_col9\" class=\"col_heading level0 col9\" >chlorides</th>\n",
       "      <th id=\"T_b704c_level0_col10\" class=\"col_heading level0 col10\" >volatile_acidity</th>\n",
       "      <th id=\"T_b704c_level0_col11\" class=\"col_heading level0 col11\" >density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
       "      <td id=\"T_b704c_row0_col0\" class=\"data row0 col0\" >60.810000</td>\n",
       "      <td id=\"T_b704c_row0_col1\" class=\"data row0 col1\" >61.000000</td>\n",
       "      <td id=\"T_b704c_row0_col2\" class=\"data row0 col2\" >60.710000</td>\n",
       "      <td id=\"T_b704c_row0_col3\" class=\"data row0 col3\" >59.400000</td>\n",
       "      <td id=\"T_b704c_row0_col4\" class=\"data row0 col4\" >59.210000</td>\n",
       "      <td id=\"T_b704c_row0_col5\" class=\"data row0 col5\" >59.770000</td>\n",
       "      <td id=\"T_b704c_row0_col6\" class=\"data row0 col6\" >59.120000</td>\n",
       "      <td id=\"T_b704c_row0_col7\" class=\"data row0 col7\" >58.830000</td>\n",
       "      <td id=\"T_b704c_row0_col8\" class=\"data row0 col8\" >58.930000</td>\n",
       "      <td id=\"T_b704c_row0_col9\" class=\"data row0 col9\" >58.740000</td>\n",
       "      <td id=\"T_b704c_row0_col10\" class=\"data row0 col10\" >54.610000</td>\n",
       "      <td id=\"T_b704c_row0_col11\" class=\"data row0 col11\" >54.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row1\" class=\"row_heading level0 row1\" >Linear Regression</th>\n",
       "      <td id=\"T_b704c_row1_col0\" class=\"data row1 col0\" >35.980000</td>\n",
       "      <td id=\"T_b704c_row1_col1\" class=\"data row1 col1\" >35.550000</td>\n",
       "      <td id=\"T_b704c_row1_col2\" class=\"data row1 col2\" >34.240000</td>\n",
       "      <td id=\"T_b704c_row1_col3\" class=\"data row1 col3\" >33.670000</td>\n",
       "      <td id=\"T_b704c_row1_col4\" class=\"data row1 col4\" >33.660000</td>\n",
       "      <td id=\"T_b704c_row1_col5\" class=\"data row1 col5\" >33.720000</td>\n",
       "      <td id=\"T_b704c_row1_col6\" class=\"data row1 col6\" >33.620000</td>\n",
       "      <td id=\"T_b704c_row1_col7\" class=\"data row1 col7\" >33.630000</td>\n",
       "      <td id=\"T_b704c_row1_col8\" class=\"data row1 col8\" >33.540000</td>\n",
       "      <td id=\"T_b704c_row1_col9\" class=\"data row1 col9\" >33.530000</td>\n",
       "      <td id=\"T_b704c_row1_col10\" class=\"data row1 col10\" >26.260000</td>\n",
       "      <td id=\"T_b704c_row1_col11\" class=\"data row1 col11\" >26.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row2\" class=\"row_heading level0 row2\" >Neighbours Classifier</th>\n",
       "      <td id=\"T_b704c_row2_col0\" class=\"data row2 col0\" >47.090000</td>\n",
       "      <td id=\"T_b704c_row2_col1\" class=\"data row2 col1\" >49.250000</td>\n",
       "      <td id=\"T_b704c_row2_col2\" class=\"data row2 col2\" >49.910000</td>\n",
       "      <td id=\"T_b704c_row2_col3\" class=\"data row2 col3\" >49.810000</td>\n",
       "      <td id=\"T_b704c_row2_col4\" class=\"data row2 col4\" >53.670000</td>\n",
       "      <td id=\"T_b704c_row2_col5\" class=\"data row2 col5\" >52.630000</td>\n",
       "      <td id=\"T_b704c_row2_col6\" class=\"data row2 col6\" >53.850000</td>\n",
       "      <td id=\"T_b704c_row2_col7\" class=\"data row2 col7\" >53.760000</td>\n",
       "      <td id=\"T_b704c_row2_col8\" class=\"data row2 col8\" >53.290000</td>\n",
       "      <td id=\"T_b704c_row2_col9\" class=\"data row2 col9\" >51.320000</td>\n",
       "      <td id=\"T_b704c_row2_col10\" class=\"data row2 col10\" >51.320000</td>\n",
       "      <td id=\"T_b704c_row2_col11\" class=\"data row2 col11\" >49.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row3\" class=\"row_heading level0 row3\" >Decision Tree</th>\n",
       "      <td id=\"T_b704c_row3_col0\" class=\"data row3 col0\" >51.600000</td>\n",
       "      <td id=\"T_b704c_row3_col1\" class=\"data row3 col1\" >51.880000</td>\n",
       "      <td id=\"T_b704c_row3_col2\" class=\"data row3 col2\" >51.220000</td>\n",
       "      <td id=\"T_b704c_row3_col3\" class=\"data row3 col3\" >51.410000</td>\n",
       "      <td id=\"T_b704c_row3_col4\" class=\"data row3 col4\" >51.410000</td>\n",
       "      <td id=\"T_b704c_row3_col5\" class=\"data row3 col5\" >52.070000</td>\n",
       "      <td id=\"T_b704c_row3_col6\" class=\"data row3 col6\" >50.000000</td>\n",
       "      <td id=\"T_b704c_row3_col7\" class=\"data row3 col7\" >46.520000</td>\n",
       "      <td id=\"T_b704c_row3_col8\" class=\"data row3 col8\" >47.270000</td>\n",
       "      <td id=\"T_b704c_row3_col9\" class=\"data row3 col9\" >50.660000</td>\n",
       "      <td id=\"T_b704c_row3_col10\" class=\"data row3 col10\" >48.210000</td>\n",
       "      <td id=\"T_b704c_row3_col11\" class=\"data row3 col11\" >55.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b704c_level0_row4\" class=\"row_heading level0 row4\" >Random Forest</th>\n",
       "      <td id=\"T_b704c_row4_col0\" class=\"data row4 col0\" >58.360000</td>\n",
       "      <td id=\"T_b704c_row4_col1\" class=\"data row4 col1\" >57.710000</td>\n",
       "      <td id=\"T_b704c_row4_col2\" class=\"data row4 col2\" >58.550000</td>\n",
       "      <td id=\"T_b704c_row4_col3\" class=\"data row4 col3\" >57.140000</td>\n",
       "      <td id=\"T_b704c_row4_col4\" class=\"data row4 col4\" >56.770000</td>\n",
       "      <td id=\"T_b704c_row4_col5\" class=\"data row4 col5\" >56.480000</td>\n",
       "      <td id=\"T_b704c_row4_col6\" class=\"data row4 col6\" >57.330000</td>\n",
       "      <td id=\"T_b704c_row4_col7\" class=\"data row4 col7\" >56.110000</td>\n",
       "      <td id=\"T_b704c_row4_col8\" class=\"data row4 col8\" >54.610000</td>\n",
       "      <td id=\"T_b704c_row4_col9\" class=\"data row4 col9\" >53.570000</td>\n",
       "      <td id=\"T_b704c_row4_col10\" class=\"data row4 col10\" >49.530000</td>\n",
       "      <td id=\"T_b704c_row4_col11\" class=\"data row4 col11\" >54.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13fa7b510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
